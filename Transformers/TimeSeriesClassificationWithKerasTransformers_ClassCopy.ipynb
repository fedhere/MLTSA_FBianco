{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fedhere/MLTSA_FBianco/blob/main/Transformers/TimeSeriesClassificationWithKerasTransformers_ClassCopy.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uPDAz7x91iGi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import keras\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def readucr(filename):\n",
        "    data = np.loadtxt(filename, delimiter=\"\\t\")\n",
        "    y = data[:, 0]\n",
        "    x = data[:, 1:]\n",
        "    return x, y.astype(int)\n",
        "\n",
        "\n",
        "root_url = \"https://raw.githubusercontent.com/hfawaz/cd-diagram/master/FordA/\"\n",
        "\n",
        "x_train, y_train = readucr(root_url + \"FordA_TRAIN.tsv\")\n",
        "x_test, y_test = readucr(root_url + \"FordA_TEST.tsv\")\n",
        "\n",
        "x_train = x_train.reshape((x_train.shape[0], x_train.shape[1], 1))\n",
        "x_test = x_test.reshape((x_test.shape[0], x_test.shape[1], 1))\n",
        "\n",
        "n_classes = len(np.unique(y_train))\n",
        "\n",
        "idx = np.random.permutation(len(x_train))\n",
        "x_train = x_train[idx]\n",
        "y_train = y_train[idx]\n",
        "\n",
        "y_train[y_train == -1] = 0\n",
        "y_test[y_test == -1] = 0\n",
        "\n",
        "input_shape = x_train.shape[1:]"
      ],
      "metadata": {
        "id": "U7IxZ1TP17Gt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(model, Xtrn, Xtst, Ytrn, Ytst):\n",
        "    cb_early = ...\n",
        "    model.fit(\n",
        "        ...\n",
        "    )\n",
        "    loss_tst, acc_tst = ...\n",
        "    print(f\"Loss calculated on the testing set: {loss_tst:.4f}\")\n",
        "    print(f\"Accuracy calculated on the testing set: {acc_tst:.4f}\")\n",
        "    return None"
      ],
      "metadata": {
        "id": "gmfg7BpP2PRV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def transformer_block(\n",
        "    x,\n",
        "    input_shape,\n",
        "    heads=...,\n",
        "    key_dim=...,\n",
        "    encoder_proj_dim=...,\n",
        "    dropout_attention=...,\n",
        "    dropout_projection=...,\n",
        "):\n",
        "    x0 = ...\n",
        "    x0 = ...\n",
        "    x0 = ...\n",
        "    x0 = ...\n",
        "\n",
        "    x1 = ...\n",
        "    x1 = ...\n",
        "    x1 = ...\n",
        "    x1 = ...\n",
        "    x1 = ...\n",
        "\n",
        "    return ...\n",
        "\n",
        "\n",
        "def build_transformer_model(\n",
        "    input_shape,\n",
        "    encoder_blocks=...,\n",
        "    feed_forward_units=[...],\n",
        "):\n",
        "    inputs = ...\n",
        "    x = ...\n",
        "\n",
        "    for ... in range(...):\n",
        "        x = ...\n",
        "\n",
        "    x = ...\n",
        "    for ... in ...:\n",
        "        x = ...\n",
        "        x = ...\n",
        "\n",
        "    outputs = ...\n",
        "    model = keras.Model(...)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "transformer_model = build_transformer_model(input_shape)\n",
        "transformer_model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=...),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "transformer_model.summary()\n",
        "\n",
        "train_and_evaluate(transformer_model, x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "ETBzP6E12S3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def build_ff_model(\n",
        "    input_shape,\n",
        "    feed_forward_units=[128]\n",
        "):\n",
        "    inputs = ...\n",
        "    x = inputs\n",
        "\n",
        "    x = ...\n",
        "    for ... in ...:\n",
        "        x = ...\n",
        "        x = ...\n",
        "\n",
        "    outputs = ...\n",
        "    model = keras.Model(..., ...)\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "input_shape = x_train.shape[1:]\n",
        "ff_model = build_ff_model(input_shape)\n",
        "ff_model.compile(\n",
        "    loss=\"sparse_categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=...),\n",
        "    metrics=[\"sparse_categorical_accuracy\"],\n",
        ")\n",
        "ff_model.summary()\n",
        "\n",
        "train_and_evaluate(ff_model, x_train, x_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "YlNQTImP67IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vv6h28dL7yYn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}