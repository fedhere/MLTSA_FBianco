{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fedhere/MLTSA_FBianco/blob/main/Code%20examples/timeSeriesClustering_populationexample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YO2n25U9uel0"
      },
      "source": [
        "# Clustering analysis on population trends\n",
        "\n",
        "You are clustering the \"shape\" of time series to find trends, specifically, population growth trends. Do any countries stand out in the population growth trends in the past 60 years? are there groups of countries that have similar trends (and why?)\n",
        "\n",
        "NOTE: your clusters may not be identical to mine!\n",
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-E7s1FM5PkHC"
      },
      "source": [
        "import pandas as pd\n",
        "import pylab as pl\n",
        "import numpy as np\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn import cluster\n",
        "\n",
        "pl.rcParams['font.size'] = 12"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "do this to read an excel file with python\n",
        "then restart the notebook"
      ],
      "metadata": {
        "id": "SviG1WzR1hup"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#need this to read the excell file with pandas\n",
        "pip install xlrd==2.0.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 106
        },
        "id": "KO6BT6pwoPHt",
        "outputId": "868e7b83-fa5a-4d92-c4b5-02f237ff470b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "invalid syntax (<ipython-input-2-6c0e650ca9fa>, line 2)",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-2-6c0e650ca9fa>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    pip install xlrd==2.0.1\u001b[0m\n\u001b[0m        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXfKxHTWuZdV"
      },
      "source": [
        "# Data processing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the data\n",
        "\n",
        "I wanted the data to be gotten from the WorldBank API directly but the link is down tonight (11/2) so I put the file on the shared drive. Mount your google drive and get it from `/content/drive/Shareddrives/PUS2022/data`. The file name is `SP.POP.TOTL?downloadformat=excel`\n",
        "\n",
        "You are going to have to skip some rows (`skiprows=`) and ideally only use relevant columns (the country name and each year column from 1960, you can use `usecold=` or you can read everything in then throw away the columns you do not need).\n",
        "\n",
        "Finally, set the country name as the index for this dataframe. you can do that with `set_index()` passing the relevant column name as the argument (dont forget that you want to do it inplace! `inplace=True`)"
      ],
      "metadata": {
        "id": "y5GuYb0FXJhR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1dJHSnWRM5f"
      },
      "source": [
        "#reading in the data\n",
        "pop_df = pd.read_excel('https://github.com/fedhere/MLTSA_FBianco/raw/refs/heads/main/data/SP.POP.TOTL_downloadformat=excel', skiprows=3)\n",
        "columns = ['Country Name', '1960', '1961', '1962', '1963', '1964', '1965', '1966', '1967', '1968',\n",
        "       '1969', '1970', '1971', '1972', '1973', '1974', '1975', '1976', '1977',\n",
        "       '1978', '1979', '1980', '1981', '1982', '1983', '1984', '1985', '1986',\n",
        "       '1987', '1988', '1989', '1990', '1991', '1992', '1993', '1994', '1995',\n",
        "       '1996', '1997', '1998', '1999', '2000', '2001', '2002', '2003', '2004',\n",
        "       '2005', '2006', '2007', '2008', '2009', '2010', '2011', '2012', '2013',\n",
        "       '2014', '2015', '2016', '2017', '2018', '2019', '2020']\n",
        "pop_df = pop_df[columns]\n",
        "pop_df.set_index(\"Country Name\", inplace=True)\n",
        "pop_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Cleaning\n",
        "remove NaNs, remove any unwanted columns"
      ],
      "metadata": {
        "id": "iMoakoRRr8A5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import missingno as mno\n",
        "mno.matrix(pop_df)"
      ],
      "metadata": {
        "id": "lJjbVxcNs7mx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pop_df.loc[pop_df.isnull().sum(axis=1) > 20]"
      ],
      "metadata": {
        "id": "LPmiTHIgtcAz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# I recommend you drop any column that is all NaN and any row that has any NaN\n",
        "# you control this (dropping only if all are, vs dropping if any is) with the keyord \"any\" of .dropna()\n",
        "pop_df_clean = pop_df.dropna(axis=1, how=\"all\")\n",
        "pop_df_clean = pop_df_clean.dropna(axis=0, how=\"all\")\n",
        "pop_df_clean.shape\n"
      ],
      "metadata": {
        "id": "eqT_MqaGawcJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pop_df_clean.dropna(axis=0, how=\"any\", inplace=True)\n",
        "pop_df_clean.shape\n"
      ],
      "metadata": {
        "id": "g98OPJG7uxM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# looking a little at the data\n",
        "print (f\"In the cleaning process we lost {np.array(pop_df.shape) - np.array(pop_df_clean.shape)} (rows, columns)\")\n",
        "print (\"In the cleaning process we lost  {:.2f}% of the data\".format(\n",
        "    100* (np.prod(np.array(pop_df.shape) - np.array(pop_df_clean.shape)) / np.prod(pop_df.shape))))"
      ],
      "metadata": {
        "id": "2YpPml-8ax_Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mno.matrix(pop_df_clean)"
      ],
      "metadata": {
        "id": "BOjjLhtMu5E0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# consider improving this! can you fill nan values with interpolation or nearest neighbours? what are the pros and cons of each choice?"
      ],
      "metadata": {
        "id": "BdPS2_qkupPv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pop_df_clean.head()"
      ],
      "metadata": {
        "id": "KgfcXLFldFGL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pop_df_clean.tail()"
      ],
      "metadata": {
        "id": "l-eoVw5kq7Bu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = pop_df_clean.T.plot(legend=False);\n",
        "ax.set_title(\"Original data\")"
      ],
      "metadata": {
        "id": "ivHpsjBCzf6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figure 1: the time series of population over time for 258 countries. Clearly the overall population size dominates the difference. General growth trends are still obvious"
      ],
      "metadata": {
        "id": "s8FXY0tU1OPU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: cluster the time series in pop_clean with kmeans into 3 clusters\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.cluster import KMeans\n",
        "\n",
        "## Scale the data\n",
        "#scaler = StandardScaler()\n",
        "#scaled_data = scaler.fit_transform(pop_df_clean)\n",
        "\n",
        "# Apply KMeans clustering\n",
        "kmeans = KMeans(n_clusters=3, random_state=0)  # Set random_state for reproducibility\n",
        "kmeans.fit(pop_df_clean)\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "pop_df_clean['cluster'] = kmeans.labels_\n",
        "\n",
        "pop_df_clean.head()\n"
      ],
      "metadata": {
        "id": "xBOlPrtu4oMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ax = pop_df_clean[pop_df_clean.cluster == 0].drop(\"cluster\", axis=1).T.plot(legend=False, color=\"k\")\n",
        "pop_df_clean[pop_df_clean.cluster == 1].drop(\"cluster\", axis=1).T.plot(ax=ax, legend=False, color=\"r\")\n",
        "pop_df_clean[pop_df_clean.cluster == 2].drop(\"cluster\", axis=1).T.plot(ax=ax, legend=False, color=\"b\")\n"
      ],
      "metadata": {
        "id": "dKMYx9L64-0S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pylab as plt\n",
        "from tqdm import tqdm\n",
        "fig, ax = plt.subplots(20, 1, figsize=(10,20))\n",
        "for i,idx in tqdm(enumerate(pop_df_clean.index[:20])):\n",
        "   pop_df_clean.loc[idx].T.plot(ax=ax[i])\n",
        "   ax[i].axis('off')\n",
        "   ax[i].text(0, pop_df_clean.loc[idx, \"1960\"], idx)\n",
        "\n"
      ],
      "metadata": {
        "id": "n5CdgCA1v7F3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figure 2: the first 30 time series in the collection shown in Figure 2, with mute axis so as to display the trend difference rather than the overall normalization. Genral growth trends are obvious but specific trends are also obvious: e.g. Bulgaria Armania and Albania have a population drop while most country have a steady increas. Clustering without normalizing did not capture this and used the mean to cluster"
      ],
      "metadata": {
        "id": "MY2HcVKt1bLl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Scale the data# standardizing the data\n",
        "X= pop_df_clean.drop(\"cluster\", axis=1).values\n",
        "scaled_data = preprocessing.scale(X, axis=0, with_mean = True, with_std = True)\n",
        "\n",
        "pod_standardized_bycol = pd.DataFrame(data=scaled_data, index = pop_df_clean.index, columns=pop_df_clean.drop(\"cluster\", axis=1).columns )\n",
        "\n",
        "fig, ax = plt.subplots(20, 1, figsize=(10,20))\n",
        "for i,idx in tqdm(enumerate(pod_standardized_bycol.index[:20])):\n",
        "   pod_standardized_bycol.loc[idx].T.plot(ax=ax[i])\n",
        "   ax[i].axis('off')\n",
        "   ax[i].text(0, pod_standardized_bycol.loc[idx, \"1960\"], idx)\n",
        "\n",
        "#pod_standardized_bycol.head()"
      ],
      "metadata": {
        "id": "8VP0oklD54hs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figure 3: the shape has changed!!! so the time series have lost their meaning. the clustering will be on what was the value at one year compared to the mean of all time series that year"
      ],
      "metadata": {
        "id": "8jxakcHp60q9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 2, figsize=(10,5))\n",
        "ax[0] = pop_df_clean.drop(\"cluster\", axis=1).T.plot(legend=False, ax=ax[0]);\n",
        "ax[0].set_title(\"Original data\")\n",
        "ax[1] = pod_standardized_bycol.T.plot(legend=False, ax=ax[1]);\n",
        "ax[1].set_title(\"Standardized by column (feature)\")"
      ],
      "metadata": {
        "id": "MXOi796B-Q4F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply KMeans clustering\n",
        "kmeans = KMeans(n_clusters=3, random_state=0)  # Set random_state for reproducibility\n",
        "kmeans.fit(scaled_data)\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "pod_standardized_bycol['cluster'] = kmeans.labels_\n",
        "\n",
        "pod_standardized_bycol.head()\n",
        "\n",
        "ax = pod_standardized_bycol[pod_standardized_bycol.cluster == 0].drop(\"cluster\", axis=1).T.plot(legend=False, color=\"k\")\n",
        "pod_standardized_bycol[pod_standardized_bycol.cluster == 1].drop(\"cluster\", axis=1).T.plot(ax=ax, legend=False, color=\"r\")\n",
        "pod_standardized_bycol[pod_standardized_bycol.cluster == 2].drop(\"cluster\", axis=1).T.plot(ax=ax, legend=False, color=\"b\")\n"
      ],
      "metadata": {
        "id": "R5-yWStfx9cE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figure 4: having standardized wrong the clustering is still based on the overall average population size in that country"
      ],
      "metadata": {
        "id": "e5j_LjpN8M8-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scaling (standardizing) correctly!"
      ],
      "metadata": {
        "id": "ECklmt0UsHz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "## Scale the data\n",
        "# standardizing the data\n",
        "X= pop_df_clean.drop(\"cluster\", axis=1).values\n",
        "scaled_data = preprocessing.scale(X, axis=1, with_mean = True, with_std = True)\n",
        "\n",
        "pod_standardized_byrow = pd.DataFrame(data=scaled_data, index = pop_df_clean.index, columns=pop_df_clean.drop(\"cluster\", axis=1).columns )\n",
        "\n",
        "fig, ax = plt.subplots(20, 1, figsize=(10,20))\n",
        "for i,idx in tqdm(enumerate(pod_standardized_byrow.index[:20])):\n",
        "   pod_standardized_byrow.loc[idx].T.plot(ax=ax[i])\n",
        "   ax[i].axis('off')\n",
        "   ax[i].text(0, pod_standardized_byrow.loc[idx, \"1960\"], idx)\n",
        "\n",
        "#pod_standardized_bycol.head()"
      ],
      "metadata": {
        "id": "Z0k9Nhyq8gSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figure 5: in this plot the time series look again like in figure 2 because each time series has been scaled but its shape has not changed.\n"
      ],
      "metadata": {
        "id": "UWjTWIKx9i2u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(1, 3, figsize=(15,5))\n",
        "ax[0] = pop_df_clean.drop(\"cluster\", axis=1).T.plot(legend=False, ax=ax[0]);\n",
        "ax[0].set_title(\"Original data\")\n",
        "ax[1] = pod_standardized_bycol.drop(\"cluster\", axis=1).T.plot(legend=False, ax=ax[1]);\n",
        "ax[1].set_title(\"Standardized by column (feature)\")\n",
        "ax[2] = pod_standardized_byrow.T.plot(legend=False, ax=ax[2]);\n",
        "ax[2].set_title(\"Standardized by column (time series)\")\n"
      ],
      "metadata": {
        "id": "74qGLdE69prs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figure 6: now the time series are standardized correctly! we can see difference in trends and cluster according to those"
      ],
      "metadata": {
        "id": "R39oaVlq92Xq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# looking at the data\n",
        "plt.plot(pod_standardized_byrow.T, color=\"k\", alpha=0.2)\n",
        "plt.xlabel(\"year\")\n",
        "plt.ylabel(\"standardized population\")\n",
        "plt.xticks(range(0,70,10), [\"%d\"%i for i in range(1960, 2030, 10)]);"
      ],
      "metadata": {
        "id": "n1MFmsMdo1K_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fig**. 7: These figures show changes in population by year. The image to the left shows the population (in billions) of differenct countries (each country represented by a color) from the year 1960 to 2020. The figure to the right shows the population of each year and country in standarized units. different trends are visible including near-linear growth, rise and fall, some dramatic drops at different times."
      ],
      "metadata": {
        "id": "XPOj1sJUo7_o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply KMeans clustering\n",
        "kmeans = KMeans(n_clusters=3, random_state=0)  # Set random_state for reproducibility\n",
        "kmeans.fit(scaled_data)\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "pod_standardized_byrow['cluster'] = kmeans.labels_\n",
        "\n",
        "pod_standardized_byrow.head()\n",
        "\n",
        "ax = pod_standardized_byrow[pod_standardized_byrow.cluster == 0].drop(\"cluster\", axis=1).T.plot(legend=False, color=\"k\", alpha=0.2)\n",
        "pod_standardized_byrow[pod_standardized_byrow.cluster == 1].drop(\"cluster\", axis=1).T.plot(ax=ax, legend=False, color=\"r\", alpha=0.2)\n",
        "pod_standardized_byrow[pod_standardized_byrow.cluster == 2].drop(\"cluster\", axis=1).T.plot(ax=ax, legend=False, color=\"b\", alpha=0.2)\n"
      ],
      "metadata": {
        "id": "wq35jL3t_1Dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figure 8: Clustering the time series after correct standardization shows three distinct trends, convex grow with increasingly rapid growing in the 2000s, concave growth with decreased growth speed in the 1990s, and a subset of countries with population size dicrease after 1990.\n"
      ],
      "metadata": {
        "id": "x-_RY2l7AemA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/wmgeolab/geoBoundaries/raw/main/releaseData/CGAZ/geoBoundariesCGAZ_ADM0.geojson\n"
      ],
      "metadata": {
        "id": "0hxZFGHdAVxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import geopandas as gpd\n",
        "countriesshp = gpd.GeoDataFrame.from_file(\"geoBoundariesCGAZ_ADM0.geojson\")\n"
      ],
      "metadata": {
        "id": "MugrkXXzBDi_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "countriesshp.replace(\"&\", \"and\")\n",
        "countriesshp.sort_values(by=\"shapeName\").shapeName.values"
      ],
      "metadata": {
        "id": "qtVAfSV6BrzZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "count = 0\n",
        "for i in pod_standardized_byrow.index:\n",
        "  if not i in countriesshp.shapeName.values:\n",
        "    count +=1\n",
        "    print(i, count)"
      ],
      "metadata": {
        "id": "32KS4wIoBwLc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = pl.subplots(1,1, figsize=(10,10))\n",
        "\n",
        "ax.set_title(\"Cluster 1 \")\n",
        "ax.set_xticks(range(0,70,10))\n",
        "ax.set_xticklabels([\"%d\"%i for i in range(1960, 2030, 10)]);\n",
        "ax.plot(pod_standardized_byrow[pod_standardized_byrow.cluster == 1 ].drop(\"cluster\", axis=1).T);\n",
        "ax.legend(labels=pod_standardized_byrow.loc[pod_standardized_byrow.cluster == 1].index, bbox_to_anchor=(1.0, 1.0), loc='upper left')\n",
        "\n"
      ],
      "metadata": {
        "id": "wH9-AwvNFtn9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mapcluster = countriesshp.merge(pod_standardized_byrow, left_on=\"shapeName\", right_index=True)\n",
        "ax = mapcluster.plot(\"cluster\", figsize=(20,20), legend=True,     categorical=True)\n",
        "plt.axis('off')"
      ],
      "metadata": {
        "id": "Vi2V51L_BMnd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: cluster the data with dbscan\n",
        "\n",
        "from sklearn.cluster import DBSCAN\n",
        "\n",
        "# Assuming 'scaled_data' from the previous code contains the correctly scaled data\n",
        "# Replace with your actual data if different.\n",
        "\n",
        "# Define DBSCAN parameters\n",
        "dbscan = DBSCAN(eps=3, min_samples=5) # Adjust eps and min_samples as needed\n",
        "\n",
        "# Fit DBSCAN to the data\n",
        "dbscan.fit(scaled_data)\n",
        "\n",
        "# Get cluster labels\n",
        "labels = dbscan.labels_\n",
        "\n",
        "# Add cluster labels to the DataFrame\n",
        "pod_standardized_byrow['cluster'] = labels\n",
        "print(pod_standardized_byrow['cluster'].unique())\n",
        "\n",
        "# Now you can analyze the clusters as you did with KMeans\n",
        "# For example:\n",
        "# Visualize clusters\n",
        "ax = pod_standardized_byrow[pod_standardized_byrow.cluster == -1].drop(\"cluster\", axis=1).T.plot(legend=False, color=\"k\", alpha=0.2)\n",
        "for l in range(0, pod_standardized_byrow['cluster'].max()+1):\n",
        "  pod_standardized_byrow[pod_standardized_byrow.cluster == l].drop(\"cluster\", axis=1).T.plot(legend=False, alpha=0.2)\n",
        "# ... plot other clusters\n",
        "\n",
        "# Evaluate the clusters as needed\n",
        "# ...\n",
        "\n",
        "\n",
        "# Example of mapping the clusters with geopandas, continuing from the original notebook\n",
        "# ...\n",
        "\n",
        "# Note: the eps and min_samples parameters are crucial. You might need to tune these\n",
        "# values based on your dataset to get meaningful results.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "T3xvSlPXDxq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Identifying the countries in the smallest clusters\n",
        "\n",
        "plot the two smallest clusters with labels for the countries"
      ],
      "metadata": {
        "id": "DBzUB8cv7ssE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = pl.subplots(1,2, figsize=(20,10))\n",
        "\n",
        "ax[0].set_title(\"Cluster 1 \")\n",
        "ax[0].set_xticks(range(0,70,10))\n",
        "ax[0].set_xticklabels([\"%d\"%i for i in range(1960, 2030, 10)]);\n",
        "ax[0].plot(pod_standardized_byrow[pod_standardized_byrow.cluster == 1 ].drop(\"cluster\", axis=1).T);\n",
        "ax[0].legend(labels=pod_standardized_byrow.loc[pod_standardized_byrow.cluster == 1].index, bbox_to_anchor=(1.0, 1.0), loc='upper left')\n",
        "\n",
        "\n",
        "ax[1].set_title(\"Cluster -1 (outliers)\")\n",
        "ax[1].set_xticks(range(0,70,10))\n",
        "ax[1].set_xticklabels([\"%d\"%i for i in range(1960, 2030, 10)]);\n",
        "ax[1].plot(pod_standardized_byrow[pod_standardized_byrow.cluster == -1 ].drop(\"cluster\", axis=1).T);\n",
        "ax[1].legend(labels=pod_standardized_byrow.loc[pod_standardized_byrow.cluster == -1].index, bbox_to_anchor=(1.0, 1.0), loc='upper left')\n",
        "# placing legend method via https://www.delftstack.com/howto/matplotlib/how-to-place-legend-outside-of-the-plot-in-matplotlib/\n",
        "\n"
      ],
      "metadata": {
        "id": "xvEEgaBnkJ3R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Figure 4: This figure shows the countries that cluster together in the smallest clusters of the sample. These two clusters are include the countries that either had a decline in population or did not have population increases.\n",
        "\n",
        "Can you do some library research to figure out why those countries may cluster together?\n",
        "\n",
        "In both cases the inflection point was around the 1990. This year was characterized by the fall of the Soviet Union that ended up in a crisis in Eastern Europe and other socialist countries."
      ],
      "metadata": {
        "id": "xFYvk2Qy7xri"
      }
    }
  ]
}